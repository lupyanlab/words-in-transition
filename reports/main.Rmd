---
title: "The emergence of lexical categories from iterated vocal imitation"
author: "Pierce Edmiston"
output:
  html_document:
    theme: flatly
    toc: true
---

```{r, config, echo = FALSE}
library(knitr)
library(printr)

opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  cache.path = ".cache/",
  fig.path = "figs/",
  fig.width = 8
)

read_chunk("5-transcription-matches/results.R")
```

```{r setup}
library(dplyr)
library(magrittr)
library(stringr)
library(ggplot2)
library(scales)
library(lme4)
library(broom)
library(AICcmodavg)

library(wordsintransition)
data("transcription_matches")

transcription_matches %<>%
  recode_question_type %>%
  recode_message_type %>%
  recode_version
```

# Determining the sounds to imitate

We started with 6 sounds in each of 6 categories and reduced that number to 4 sounds in each of 4 categories through two "odd one out" norming experiments.

# Collecting iterated imitations

# Matching imitations to original sounds

# Collecting transcriptions of sounds

## Methods

### Selected sounds

Transcribed sounds include all 16 seed sound effects and all imitatations in the last generation of each iteration chain.

## Results

There was less agreement among transcribers for the seed sound effects
than there was among the transcribers of n-th generation imitations.

```{r, fig.width = 4}
transcription_frequencies %<>%
  mutate(message_id = imitation_id) %>%
  recode_message_type

transcription_uniqueness <- transcription_frequencies %>%
  group_by(message_type, message_id) %>%
  summarize(
    num_words = sum(n),
    num_unique = n_distinct(text),
    perct_unique = num_unique/num_words
  )

ggplot(transcription_uniqueness, aes(x = message_type, y = perct_unique)) +
  geom_point(position = position_jitter(0.1, 0.0), shape = 1) +
  geom_point(stat = "summary", fun.y = "mean", size = 2)
```

# Matching transcriptions to original sounds

```{r 5-setup}
```

## Methods

### Selected transcriptions

We obtained match-to-seed accuracy ratings for the 4 most frequent spellings
of a sample of 8 transcribed sounds.

### Subjects

```{r, 5-subjects}
transcription_matches %>%
  group_by(version) %>%
  summarize(
    num_subjects = length(unique(subj_id)),
    num_responses_per_subject = round(n()/num_subjects)
  ) %>%
  kable(col.names = c("Version", "Subjects", "Responses per subject"),
        align = "l")
```

Subjects were excluded if they failed the catch trial, which indicated
that they should select the third option.

```{r, 5-catch-trials, fig.width = 4}
```

## Results

```{r, 5-plot-template}
```

```{r, 5-plot-means}
```

```{r, 5-model, echo = 1, cache = TRUE}
```

```{r, 5-model-preds}
```

### Agreement as a predictor of matching accuracy

Do the imitations where there is a lot of agreement in the transcriptions have higher matching accuracy?