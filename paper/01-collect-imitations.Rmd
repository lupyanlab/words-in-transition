# Collecting imitations

We collected vocal imitations by conducting a version of the children's game
"telephone" online. Starting with the selected seeds, participants imitated either the seed sounds directly or someone's imitation of the seed sound that had been passed down transmission chains of unique participants.

```{r include=FALSE}
library(tidyverse)
library(magrittr)
library(lme4)
library(AICcmodavg)

library(wordsintransition)
data("sound_similarity_6")
data("sound_similarity_4")
data("final_seeds")
data("imitations")
data("subjects")
data("acoustic_similarity_judgments")

global_theme <- theme_minimal() +
  theme(
    axis.ticks = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )

drop_bad_trials <- . %>%
  filter(failed_catch_trial == 0, problem_with_audio == 0)

recode_filename <- function(frame, custom_levels) {
  if (!missing(custom_levels)) filename_levels <- custom_levels
  frame %>%
    mutate(filename_f = factor(filename, levels = filename_levels))
}

count_responses <- function(frame, filename_levels) {
  frame %>%
    drop_bad_trials() %>%
    recode_filename(custom_levels = filename_levels) %>%
    count(filename_f) %>%
    select(filename_f, n) %>%
    complete(filename_f, fill = list(n = 0)) %>%
    mutate(filename = as.character(filename_f)) %>%
    left_join(filename_map) %>%
    arrange(category, desc(n))
}

z_score_by_subj <- function(frame) {
  z_score <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  frame %>%
    group_by(name) %>%
    mutate(similarity_z = z_score(similarity)) %>%
    ungroup()
}

recode_edge_generations <- function(frame) {
  data_frame(
    edge_generations = c("1-2", "2-3", "3-4", "4-5", "5-6", "6-7", "7-8"),
    edge_generation_n = seq_along(edge_generations)
  ) %>%
    left_join(frame, .)
}

determine_trial_id <- function(frame) {
  # Warning! Ignores presentation order.
  mutate(frame, trial_id = paste(sound_x, ":", sound_y))
}

# Create a factor for ordered and missing filenames.
filename_map <- expand.grid(
    category = unique(sound_similarity_6$category),
    ix = 1:6
  ) %>%
  mutate(filename = paste0(category, "_0", ix, ".mp3")) %>%
  arrange(category, ix) %>%
  select(category, filename)

filename_levels <- filename_map$filename
sound_similarity_6_counts <- sound_similarity_6 %>%
  count_responses(filename_levels) %>%
  # label two most frequently selected messages as odd
  group_by(category) %>%
  mutate(odd_one_out = ifelse(n >= n[2], "odd", "normal")) %>%
  ungroup()

kept <- sound_similarity_6_counts %>%
  filter(odd_one_out == "normal") %>%
  .$filename %>%
  unique()

filename_levels <- filename_levels[filename_levels %in% kept]
final_categories <- c("water", "tear", "zipper", "glass")
sound_similarity_4_counts <- sound_similarity_4 %>%
  count_responses(filename_levels) %>%
  # label categories used in final experiment
  mutate(odd_one_out = ifelse(category %in% final_categories, "normal", "odd"))

acoustic_similarity_judgments %<>%
  mutate(similarity = ifelse(similarity == -1, NA, similarity)) %>%
  z_score_by_subj() %>%
  recode_edge_generations() %>%
  determine_trial_id()
```

## Methods

### Seed selection

Our goal in selecting sounds to serve as seeds in the transmission chains was to
pick multiple sounds within a few different categories such that each category 
member was approximately equally distinguishable from the other sounds within 
the same category. To do this, we started with an initial set of 6 categories 
and 6 sounds in each category and conducted 2 rounds of "odd one out" norming to
reduce the initial set to a final set of 16 seed sounds: 4 sounds in each of 4
categories.

```{r 1-seed-selection, results="asis", echo=FALSE}
summarize_participants <- function(frame, round_n) {
  dropped <- frame %>%
    filter(failed_catch_trial == 1) %>%
    .$workerId %>%
    unique() %>%
    length()

  data_frame(
    Round = round_n,
    N = length(unique(frame$workerId)),
    Dropped = dropped
  )
}


rbind(
  summarize_participants(sound_similarity_6, 1),
  summarize_participants(sound_similarity_4, 2)
) %>%
  pander::pandoc.table()
```

Participants in the odd one out norming procedure listened to the sounds in each
category and picked the one that they thought was **the most different** from
the others. In the first round of norming, participants listened to 6 sounds on
a given trial. We removed the sounds in each category that were the most
different from the others, and repeated the norming process again with 5 sounds
in each category. The resulting sounds that were selected in each category are
considered to be a set of equally distinguishable category members.

```{r 1-odd-one-out, include=FALSE}
odd_one_out <- ggplot(mapping = aes(x = filename_f, y = n)) +
  geom_bar(aes(fill = odd_one_out), stat = "identity") +
  scale_x_discrete("") +
  scale_y_continuous("Number of times selected as odd one out") +
  scale_fill_manual("", labels = c("kept", "dropped"),
                    values = RColorBrewer::brewer.pal(3, "Set2")[c(1, 2)]) +
  facet_wrap("category", scales = "free_x", ncol = 2) +
  theme_minimal() +
  theme(
    axis.ticks = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.direction = "vertical",
    legend.position = c(0.06, 1.0)
  )
```

```{r 1-odd-one-out-1, echo=FALSE, fig.height=10, fig.cap="Results of the first round of seed norming. After collecting these data, two sounds were removed from each category and the norming procedure was conducted again."}
(odd_one_out %+% sound_similarity_6_counts) +
  ggtitle("Odd one out (6 per category)")
```

```{r 1-odd-one-out-2, echo=FALSE, fig.height=10, fig.cap="Results of the second round of seed norming. After collecting these data, four categories of sounds were selected to use in the main experiment."}
(odd_one_out %+% sound_similarity_4_counts) +
  ggtitle("Odd one out (4 per category)")
```

```{r 1-final-seeds, echo=FALSE, results="asis"}
# The audio only works with html obviously but whatever goes between
# the audio tags will be rendered in pdf/word outputs.
player <- '<audio src="%s" controls>%s</audio>'
caption <- "Environmental sounds used as \"seed messages\" in the experiment."

final_seeds %>%
  mutate(
    url = paste0('http://sapir.psych.wisc.edu/telephone/seeds/', filename),
    # A markdown link is required in order to render properly in pdf/word.
    link = sprintf('[%s](%s)', filename, url),
    play = sprintf(player, url, link)
  ) %>%
  select(Category = category, Exemplar = play) %>%
  arrange(Category) %>%
  pander::pandoc.table(justify = "left", split.tables = Inf, caption = caption)
```

### Design

```{r 1-definitions, engine="dot", cache=FALSE, code=readLines(crotchet::find_graphviz("definitions", "wordsintransition")), fig.width=2, fig.cap="Design for the telephone game experiment. Imitations were gathered from four categories of sounds and from four seeds within each category. Each seed sound was imitated by four different participants, leading to four different branches off of each seed sound. Branches were allowed to run out for up to 8 generations."}
```

### Participants

Participants were recruited via Amazon's Mechanical Turk. Eligible participants were based in the United States and had a working microphone for recording the imitations.

```{r 1-participants, echo=FALSE, results="asis"}
data_frame(
  Experiment = c("Collect imitations", "Judge similarity"),
  N = c(
    round(nrow(imitations %>% filter(generation > 0))/4, 0),
    length(unique(acoustic_similarity_judgments$name))
  )
) %>%
  pander::pandoc.table()
```

### Procedure

Participants were given a link to the experiment. The experiment was introduced as a version of the children's game "telephone" where an auditory message is passed from person to person with the goal of leaving the original message unchanged. They were told that the messages they would hear might not be recognizable as English words (as they typically are in the children's game), but that their goal was the same: to repeat whatever they heard as accurately as possible. Participants then listened to messages one at a time and recorded their imitation of it for a total of four messages and imitations. The average time to complete this experiment was less than 5 minutes.

```{r 1-telephone-gui, fig.width=3, fig.height=3, fig.cap="The interface for the telephone game. Initially the only action open to players is to hear the message by clicking the top sound icon. After listening to the message once, they could then initiate a recording of their imitation by clicking the bottom sound icon. Turning the recorder off submitted their response, and a new message was loaded."}
library(grid)
library(png)
grid.newpage()
grid.draw(readPNG("img/telephone.png") %>% rasterGrob())
```

### Acoustic similarity judgments

## Results

```{r 1-acoustic-similarity-mod, echo=1}
similarity_mod <- lmer(
  similarity_z ~ edge_generation_n + (edge_generation_n|name) + (edge_generation_n|category),
  data = acoustic_similarity_judgments
)

similarity_preds <- data_frame(edge_generation_n = 1:7) %>%
  cbind(., predictSE(similarity_mod, newdata = ., se = TRUE)) %>%
  rename(similarity_z = fit, se = se.fit) %>%
  recode_edge_generations
```

```{r, results="asis"}
broom::tidy(similarity_mod, effects="fixed") %>%
  knitr::kable(digits = 2)
```

```{r 1-similarity-judgments-plot}
similarity_judgments_means <- acoustic_similarity_judgments %>%
  group_by(edge_generations, category) %>%
  summarize(similarity_z = mean(similarity_z, na.rm = TRUE)) %>%
  recode_edge_generations

set.seed(949)
gg_similarity_judgments <- ggplot(similarity_judgments_means) +
  aes(x = edge_generations, y = similarity_z) +
  geom_point(aes(color = category), position = position_jitter(0.6, 0.0),
             size = 2, alpha = 0.8) +
  geom_smooth(aes(group = 1, ymin = similarity_z - se, ymax = similarity_z + se),
              data = similarity_preds, stat = "identity",
              alpha = 0.2, color = "gray") +
  scale_x_discrete("Generation") +
  scale_y_continuous("Acoustic similarity") +
  scale_color_brewer("Category", palette = "Set2") +
  global_theme +
  theme(legend.position = "top")
gg_similarity_judgments
```

## Discussion